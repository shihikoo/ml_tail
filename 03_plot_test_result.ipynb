{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # This is to disable GPU\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\" \n",
    "\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "import importlib\n",
    "import swifter\n",
    "import plot_functions\n",
    "import ml_wrappers\n",
    "import functions\n",
    "import pytplot\n",
    "from pyspedas import time_double\n",
    "from pyspedas import time_string\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "# warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "importlib.reload(ml_wrappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2677a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = ''\n",
    "\n",
    "data_dir = main_dir+'data/'\n",
    "os.makedirs(data_dir, exist_ok = True) \n",
    "model_dir = main_dir+'model/'\n",
    "os.makedirs(model_dir, exist_ok = True)\n",
    "result_dir = main_dir+'test_results/'\n",
    "os.makedirs(result_dir, exist_ok = True) \n",
    "\n",
    "average_time = 300\n",
    "\n",
    "plot_inputs = False\n",
    "\n",
    "dL01 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30343bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, 5 minutes resolution data, including omni data and cluster data. \n",
    "df_a= pd.read_csv(data_dir+'rbspA_data_fulldata.csv')  \n",
    "df_a['probe'] = 'a'\n",
    "df_b= pd.read_csv(data_dir+'rbspB_data_fulldata.csv')  \n",
    "df_b['probe'] = 'b'\n",
    "\n",
    "df_full = pd.concat([df_a, df_b], ignore_index=True) # all data\n",
    "del df_a, df_b\n",
    "df_full['Datetime'] = df_full['time'].swifter.apply(time_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the parameters and y that are used in the code\n",
    "coor_names = [\"cos0\", 'sin0', 'scaled_lat','scaled_l']\n",
    "feature_names = [ 'scaled_symh', 'scaled_ae','scaled_asyh', 'scaled_asyd'] #,'scaled_swp', 'scaled_bz'] #, 'scaled_f107', 'scaled_kp']\n",
    "\n",
    "y_names_total = [['log_h_flux_972237','log_o_flux_972237'], ['log_h_flux_9631899','log_o_flux_9631899'],['log_h_flux_51767680','log_o_flux_51767680']]\n",
    "y_names = y_names_total[2]\n",
    "\n",
    "y_names_original = [s.replace(\"log_\",\"\") for s in y_names]\n",
    "#y_name_original = y_name.replace(\"log_\",\"\")\n",
    "\n",
    "models =  [model_dir + s + '.h5' for s in y_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the length the parameters\n",
    "m_coor = len(coor_names)\n",
    "m_y = len(y_names)\n",
    "m_feature = len(feature_names)\n",
    "# For each feature, we will add 2 hours earlier of the parametners: feature_1 no delay, feautre_2, 2 hours before the observing time, feature_3, 4 hours before the observation time.\n",
    "# Time reslution is set to be two hours for each feature and \n",
    "n_history_total_days = 6\n",
    "n_history_total = n_history_total_days*24*60*60/average_time \n",
    "\n",
    "m_history = int(n_history_total/24 + 1)\n",
    "\n",
    "# m is the total number of parameters including features and y\n",
    "m = m_feature * m_history + m_coor + m_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3afb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are non valid data in the situ observations, index data and solar wind data. Indexes of valid data are created. We have previousely reviewed that all coordinates data and all indexes data do not have NaN or Inf data. \n",
    "index_good_index = (df_full['ae'] > 0)\n",
    "index_good_sw = np.isfinite(df_full['swp']) & np.isfinite(df_full['bz'])\n",
    "index_good_y = np.isfinite(df_full[y_names_original[0]]) & np.isfinite(df_full[y_names_original[1]]) & (df_full[y_names_original[0]] > 0) & (df_full[y_names_original[1]] > 0) # we take out 0 measurement data because we are using the log\n",
    "\n",
    "# if we decide to use solar wind parameters, we need to add index_good_sw\n",
    "index_good = index_good_y & index_good_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273efe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to to keep only 1 data sample per 0.1 L shell, set dL01=True \n",
    "if (dL01):\n",
    "    df_full[\"l10\"] = df_full[\"l\"].swifter.apply(lambda x: np.floor(x*10))\n",
    "    df_full[\"l10_pre\"] = np.append(0,np.array(df_full.loc[0:(df_full.shape[0]-2), \"l10\"]))\n",
    "    df_full['isMask'] = df_full[\"l10\"] ==  df_full[\"l10_pre\"]\n",
    "    index_good = index_good & ~df_full['isMask']\n",
    "# df_full[['l','l10','l10_pre','isMask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = sum(index_good)\n",
    "print('Total number of valid 5-minutes samples is:', n_sample)\n",
    "\n",
    "# create time_array for plotting the data\n",
    "time_array = df_full.loc[index_good,'Datetime'].astype('datetime64[ns]').reset_index(drop=True)\n",
    "\n",
    "# View the summary of the datetime. Makesure that the first date of the valid data has enough history days.\n",
    "df_full.loc[index_good, 'Datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87096d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Take log10 for the flux. This step is essential \n",
    "# df_full[y_names] = df_full.loc[:,y_names_original].apply(lambda x: np.log10(x*1e3*4*math.pi))\n",
    "df_full[y_names] = df_full.loc[index_good,y_names_original].swifter.apply(lambda x: np.log10(x*1e3*4*math.pi))\n",
    "\n",
    "# visualize plasma data\n",
    "if (plot_inputs):\n",
    "    plot_functions.view_data(df_full,index_good, [y_names_original[iy],y_names[iy],y_names_original[iy], y_names[iy]], ['H+ 51767.680 eV','log H+ 51767.680 eV','O+ 51767.680 eV','log O+ 51767.680 eV'], time_array, figname = result_dir + 'rbsp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e38ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scale coordinates L, cos(theta),sin(theta),Lat. All are scaled linearly to [-1,1]\n",
    "df_full['cos0'] = df_full['mlt'].swifter.apply(lambda x: np.cos(x*np.pi/12.0))\n",
    "df_full['sin0'] = df_full['mlt'].swifter.apply(lambda x: np.sin(x*np.pi/12.0))\n",
    "df_full.loc[index_good, 'scaled_l'] = functions.scale_arr(df_full.loc[index_good, 'l']) # here only scales the good data\n",
    "df_full.loc[index_good, 'scaled_lat'] = functions.scale_arr(df_full.loc[index_good, 'lat'])# here only scales the good data\n",
    "\n",
    "if (plot_inputs):\n",
    "    plot_functions.view_data(df_full,index_good, ['mlt',\"cos0\",'sin0','l','scaled_l','lat','scaled_lat'], ['MLT','cos theta','sin theta','L','scaled L','LAT','scaled LAT'], time_array, figname = result_dir + 'coor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0becf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scale indexes\n",
    "df_full['scaled_symh'] = functions.scale_arr(df_full['symh'])\n",
    "df_full['scaled_asyh'] = functions.scale_arr(df_full['asyh'])\n",
    "df_full['scaled_asyd'] = functions.scale_arr(df_full['asyd'])\n",
    "df_full['scaled_ae'] = functions.scale_arr(df_full['ae'])\n",
    "df_full['scaled_f107'] = functions.scale_arr(df_full['f10.7'])\n",
    "df_full['scaled_kp'] = functions.scale_arr(df_full['kp'])\n",
    "\n",
    "if (plot_inputs):\n",
    "    plot_functions.view_data(df_full,index_good, ['symh',\"scaled_symh\",'asyh','scaled_asyh','asyd','scaled_asyd','ae','scaled_ae','f10.7','scaled_f107','scaled_kp','kp'], ['Sym-H', \"Scaled Sym-H\", 'Asy-H','Scaled Asy-H','Asy-D','Scaled Asy-D','AE','Scaled AE','F10.7','Scaled F10.7', 'Scaled KP','KP'], time_array, figname = result_dir + 'omni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a130a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scale solar wind drivers\n",
    "df_full['scaled_swp'] = functions.scale_arr(df_full['swp'])\n",
    "df_full['scaled_swn'] = functions.scale_arr(df_full['swn'])\n",
    "df_full['scaled_swv'] = functions.scale_arr(df_full['swv'])\n",
    "df_full['scaled_by'] = functions.scale_arr(df_full['by'])\n",
    "df_full['scaled_bz'] = functions.scale_arr(df_full['bz'])\n",
    "\n",
    "# Visualize solar wind drivers\n",
    "if (plot_inputs):\n",
    "    plot_functions.view_data(df_full,index_good, ['swp',\"scaled_swp\",'swn','scaled_swn','swv','scaled_swv','by','scaled_by',\"bz\",\"scaled_bz\"], ['SW P','scaled SW P','SW N','scaled SW N','SW V','scaled SW V','IMF By','scaled IMF By','IMF Bz','scaled IMF Bz'], time_array, figname = result_dir + 'sw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate history of the solar wind driver and geomagentic indexes\n",
    "\n",
    "history_resolution = 2 * 3600.\n",
    "index_difference = history_resolution/average_time\n",
    "history_feature_names = [\"\" for x in range(len(feature_names)*m_history)]\n",
    "ihf= 0\n",
    "index0 = n_history_total\n",
    "index1 = df_full.index[-1]\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    for k in range(m_history):\n",
    "        name = feature_name + '_' + str(k*2)+'h'\n",
    "        history_feature_names[ihf] = name\n",
    "        df_full.loc[index0:index1,name] = np.array(df_full.loc[(index0 - index_difference*k):(index1-index_difference*k), feature_name])  \n",
    "        ihf = ihf + 1\n",
    "        \n",
    "## This method is slow but good if different history calculation is wanted\n",
    "# def calculate_history(x, df_full, feature_name):\n",
    "#     index = df_full['time'] == (x-history_resolution)\n",
    "#     return(float(df_full.loc[index,feature_name]))\n",
    "\n",
    "# history_resolution = 2 * 3600.\n",
    "# for feature_name in feature_names:\n",
    "#     print(feature_name)\n",
    "#     for k in range(m_history):\n",
    "#         print(k)\n",
    "#         name = feature_name + '_' + str(k*2)+'h'\n",
    "#         df[name] = df.loc[:,'time'].swifter.apply(calculate_history, df_full = df_full,feature_name = feature_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set test set. Here we use one year (2017) of data for test set \n",
    "index_train, index_valid,index_test =  ml_wrappers.create_ml_indexes(df_full, '2017-01-01', '2018-01-01', index_good, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f886c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importlib.reload(ml_wrappers)\n",
    "\n",
    "# Each round, one can only train one y. If train more than one y, need to  repeat from here\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = ml_wrappers.create_ml_data(df_full, index_train, index_valid,index_test, y_names, coor_names, history_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b646c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plot_functions)\n",
    "# calculate test result\n",
    "\n",
    "inner_model = list()\n",
    "y_test_pred = list()\n",
    "y_test_pred_reshaped = list()\n",
    "for iy in range(len(y_names)):\n",
    "    inner_model.append(tf.keras.models.load_model(models[iy]))\n",
    "    \n",
    "    y_test_pred.append(inner_model[iy].predict(x_test))\n",
    "    y_test_pred_reshaped.append(y_test_pred[iy].reshape([-1]))\n",
    "    plot_functions.plot_correlation_heatmap(y_test[:,iy], y_test_pred[iy].reshape([-1]), xrange=[1,8], figname = result_dir + y_names[iy]+'_test_r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3385f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following sections are to visulize the long-term variation of modeled proton flux\n",
    "importlib.reload(plot_functions)\n",
    "\n",
    "omni_ts, y_data_ts, y_pred_ts, y_diff_ts = plot_functions.create_time_series_variables(df_full, index_test, y_names, y_test_pred_reshaped, to_plot_omni_list=['symh'], to_plot_omni_label_list = ['SymH (nT)'])\n",
    "\n",
    "plot_functions.plot_test_tplot(omni_ts, y_data_ts, y_pred_ts, y_diff_ts, filename = result_dir +'test_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2d134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ef7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c587a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e135c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
